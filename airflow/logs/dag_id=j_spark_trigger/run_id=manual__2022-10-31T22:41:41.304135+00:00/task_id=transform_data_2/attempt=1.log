[2022-10-31T22:41:44.226+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: j_spark_trigger.transform_data_2 manual__2022-10-31T22:41:41.304135+00:00 [queued]>
[2022-10-31T22:41:44.237+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: j_spark_trigger.transform_data_2 manual__2022-10-31T22:41:41.304135+00:00 [queued]>
[2022-10-31T22:41:44.238+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-10-31T22:41:44.239+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2022-10-31T22:41:44.240+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-10-31T22:41:44.251+0000] {taskinstance.py:1383} INFO - Executing <Task(BashOperator): transform_data_2> on 2022-10-31 22:41:41.304135+00:00
[2022-10-31T22:41:44.265+0000] {standard_task_runner.py:54} INFO - Started process 5172 to run task
[2022-10-31T22:41:44.268+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'j_spark_trigger', 'transform_data_2', 'manual__2022-10-31T22:41:41.304135+00:00', '--job-id', '126', '--raw', '--subdir', 'DAGS_FOLDER/j_spark_trigger.py', '--cfg-path', '/tmp/tmpdncn3ulz']
[2022-10-31T22:41:44.270+0000] {standard_task_runner.py:83} INFO - Job 126: Subtask transform_data_2
[2022-10-31T22:41:44.272+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/***/dags/j_spark_trigger.py
[2022-10-31T22:41:44.387+0000] {task_command.py:384} INFO - Running <TaskInstance: j_spark_trigger.transform_data_2 manual__2022-10-31T22:41:41.304135+00:00 [running]> on host 3feaf0e3bdbf
[2022-10-31T22:41:44.448+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=***@example.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=j_spark_trigger
AIRFLOW_CTX_TASK_ID=transform_data_2
AIRFLOW_CTX_EXECUTION_DATE=2022-10-31T22:41:41.304135+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-10-31T22:41:41.304135+00:00
[2022-10-31T22:41:44.452+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2022-10-31T22:41:44.454+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', '/opt/spark/bin/spark-submit /mnt/script-2.py']
[2022-10-31T22:41:44.469+0000] {subprocess.py:86} INFO - Output:
[2022-10-31T22:41:47.236+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO SparkContext: Running Spark version 3.3.0
[2022-10-31T22:41:47.292+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2022-10-31T22:41:47.371+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO ResourceUtils: ==============================================================
[2022-10-31T22:41:47.375+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO ResourceUtils: No custom resources configured for spark.driver.
[2022-10-31T22:41:47.378+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO ResourceUtils: ==============================================================
[2022-10-31T22:41:47.381+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO SparkContext: Submitted application: script-2.py
[2022-10-31T22:41:47.399+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2022-10-31T22:41:47.411+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO ResourceProfile: Limiting resource is cpu
[2022-10-31T22:41:47.415+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2022-10-31T22:41:47.480+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO SecurityManager: Changing view acls to: ***
[2022-10-31T22:41:47.483+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO SecurityManager: Changing modify acls to: ***
[2022-10-31T22:41:47.496+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO SecurityManager: Changing view acls groups to:
[2022-10-31T22:41:47.500+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO SecurityManager: Changing modify acls groups to:
[2022-10-31T22:41:47.502+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(***); groups with view permissions: Set(); users  with modify permissions: Set(***); groups with modify permissions: Set()
[2022-10-31T22:41:47.790+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO Utils: Successfully started service 'sparkDriver' on port 40555.
[2022-10-31T22:41:47.825+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO SparkEnv: Registering MapOutputTracker
[2022-10-31T22:41:47.864+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO SparkEnv: Registering BlockManagerMaster
[2022-10-31T22:41:47.881+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2022-10-31T22:41:47.887+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2022-10-31T22:41:47.894+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2022-10-31T22:41:47.925+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0b3184cb-ff6e-4bd1-a812-2cff5266b3cb
[2022-10-31T22:41:47.976+0000] {subprocess.py:93} INFO - 22/10/31 22:41:47 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2022-10-31T22:41:48.049+0000] {subprocess.py:93} INFO - 22/10/31 22:41:48 INFO SparkEnv: Registering OutputCommitCoordinator
[2022-10-31T22:41:48.488+0000] {subprocess.py:93} INFO - 22/10/31 22:41:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2022-10-31T22:41:48.693+0000] {subprocess.py:93} INFO - 22/10/31 22:41:48 INFO Executor: Starting executor ID driver on host 3feaf0e3bdbf
[2022-10-31T22:41:48.711+0000] {subprocess.py:93} INFO - 22/10/31 22:41:48 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2022-10-31T22:41:48.738+0000] {subprocess.py:93} INFO - 22/10/31 22:41:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42787.
[2022-10-31T22:41:48.747+0000] {subprocess.py:93} INFO - 22/10/31 22:41:48 INFO NettyBlockTransferService: Server created on 3feaf0e3bdbf:42787
[2022-10-31T22:41:48.754+0000] {subprocess.py:93} INFO - 22/10/31 22:41:48 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2022-10-31T22:41:48.760+0000] {subprocess.py:93} INFO - 22/10/31 22:41:48 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 3feaf0e3bdbf, 42787, None)
[2022-10-31T22:41:48.766+0000] {subprocess.py:93} INFO - 22/10/31 22:41:48 INFO BlockManagerMasterEndpoint: Registering block manager 3feaf0e3bdbf:42787 with 434.4 MiB RAM, BlockManagerId(driver, 3feaf0e3bdbf, 42787, None)
[2022-10-31T22:41:48.771+0000] {subprocess.py:93} INFO - 22/10/31 22:41:48 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 3feaf0e3bdbf, 42787, None)
[2022-10-31T22:41:48.774+0000] {subprocess.py:93} INFO - 22/10/31 22:41:48 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 3feaf0e3bdbf, 42787, None)
[2022-10-31T22:41:51.428+0000] {subprocess.py:93} INFO - 22/10/31 22:41:51 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2022-10-31T22:41:51.444+0000] {subprocess.py:93} INFO - 22/10/31 22:41:51 INFO SharedState: Warehouse path is 'file:/tmp/***tmpi7l624q6/spark-warehouse'.
[2022-10-31T22:42:22.475+0000] {subprocess.py:93} INFO - 22/10/31 22:42:22 INFO CodeGenerator: Code generated in 2111.189501 ms
[2022-10-31T22:42:23.294+0000] {subprocess.py:93} INFO - 22/10/31 22:42:23 INFO DAGScheduler: Registering RDD 3 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2022-10-31T22:42:23.333+0000] {subprocess.py:93} INFO - 22/10/31 22:42:23 INFO DAGScheduler: Got map stage job 0 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-10-31T22:42:23.338+0000] {subprocess.py:93} INFO - 22/10/31 22:42:23 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (save at NativeMethodAccessorImpl.java:0)
[2022-10-31T22:42:23.354+0000] {subprocess.py:93} INFO - 22/10/31 22:42:23 INFO DAGScheduler: Parents of final stage: List()
[2022-10-31T22:42:23.361+0000] {subprocess.py:93} INFO - 22/10/31 22:42:23 INFO DAGScheduler: Missing parents: List()
[2022-10-31T22:42:23.366+0000] {subprocess.py:93} INFO - 22/10/31 22:42:23 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-10-31T22:42:23.377+0000] {subprocess.py:93} INFO - 22/10/31 22:42:23 INFO CodeGenerator: Code generated in 80.959667 ms
[2022-10-31T22:42:23.914+0000] {subprocess.py:93} INFO - 22/10/31 22:42:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 13.3 KiB, free 434.4 MiB)
[2022-10-31T22:42:24.057+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 434.4 MiB)
[2022-10-31T22:42:24.083+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 3feaf0e3bdbf:42787 (size: 7.0 KiB, free: 434.4 MiB)
[2022-10-31T22:42:24.101+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513
[2022-10-31T22:42:24.166+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-10-31T22:42:24.177+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2022-10-31T22:42:24.401+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO DAGScheduler: Registering RDD 5 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2022-10-31T22:42:24.409+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO DAGScheduler: Got map stage job 1 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-10-31T22:42:24.414+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (save at NativeMethodAccessorImpl.java:0)
[2022-10-31T22:42:24.426+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO DAGScheduler: Parents of final stage: List()
[2022-10-31T22:42:24.430+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO DAGScheduler: Missing parents: List()
[2022-10-31T22:42:24.434+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-10-31T22:42:24.454+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.9 KiB, free 434.4 MiB)
[2022-10-31T22:42:24.472+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 434.4 MiB)
[2022-10-31T22:42:24.486+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 3feaf0e3bdbf:42787 (size: 6.9 KiB, free: 434.4 MiB)
[2022-10-31T22:42:24.491+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
[2022-10-31T22:42:24.499+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-10-31T22:42:24.516+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2022-10-31T22:42:24.533+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (3feaf0e3bdbf, executor driver, partition 0, PROCESS_LOCAL, 4288 bytes) taskResourceAssignments Map()
[2022-10-31T22:42:24.557+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (3feaf0e3bdbf, executor driver, partition 0, PROCESS_LOCAL, 4288 bytes) taskResourceAssignments Map()
[2022-10-31T22:42:24.587+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2022-10-31T22:42:24.594+0000] {subprocess.py:93} INFO - 22/10/31 22:42:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
[2022-10-31T22:42:25.471+0000] {subprocess.py:93} INFO - 22/10/31 22:42:25 INFO CodeGenerator: Code generated in 67.133792 ms
[2022-10-31T22:42:25.478+0000] {subprocess.py:93} INFO - 22/10/31 22:42:25 INFO CodeGenerator: Code generated in 66.096042 ms
[2022-10-31T22:42:25.973+0000] {subprocess.py:93} INFO - 22/10/31 22:42:25 INFO JDBCRDD: closed connection
[2022-10-31T22:42:26.011+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO JDBCRDD: closed connection
[2022-10-31T22:42:26.178+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2028 bytes result sent to driver
[2022-10-31T22:42:26.183+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2028 bytes result sent to driver
[2022-10-31T22:42:26.204+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1735 ms on 3feaf0e3bdbf (executor driver) (1/1)
[2022-10-31T22:42:26.208+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2022-10-31T22:42:26.211+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1660 ms on 3feaf0e3bdbf (executor driver) (1/1)
[2022-10-31T22:42:26.219+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2022-10-31T22:42:26.242+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO DAGScheduler: ShuffleMapStage 0 (save at NativeMethodAccessorImpl.java:0) finished in 2.834 s
[2022-10-31T22:42:26.246+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO DAGScheduler: looking for newly runnable stages
[2022-10-31T22:42:26.250+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO DAGScheduler: running: Set(ShuffleMapStage 1)
[2022-10-31T22:42:26.258+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO DAGScheduler: waiting: Set()
[2022-10-31T22:42:26.260+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO DAGScheduler: failed: Set()
[2022-10-31T22:42:26.297+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO DAGScheduler: ShuffleMapStage 1 (save at NativeMethodAccessorImpl.java:0) finished in 1.861 s
[2022-10-31T22:42:26.303+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO DAGScheduler: looking for newly runnable stages
[2022-10-31T22:42:26.307+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO DAGScheduler: running: Set()
[2022-10-31T22:42:26.311+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO DAGScheduler: waiting: Set()
[2022-10-31T22:42:26.313+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO DAGScheduler: failed: Set()
[2022-10-31T22:42:26.492+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2022-10-31T22:42:26.705+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2022-10-31T22:42:26.721+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2022-10-31T22:42:26.729+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO DAGScheduler: Final stage: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2022-10-31T22:42:26.736+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
[2022-10-31T22:42:26.742+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO DAGScheduler: Missing parents: List()
[2022-10-31T22:42:26.752+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[7] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2022-10-31T22:42:26.801+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.2 KiB, free 434.4 MiB)
[2022-10-31T22:42:26.835+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 434.4 MiB)
[2022-10-31T22:42:26.842+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 3feaf0e3bdbf:42787 (size: 3.8 KiB, free: 434.4 MiB)
[2022-10-31T22:42:26.845+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1513
[2022-10-31T22:42:26.848+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[7] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2022-10-31T22:42:26.854+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2022-10-31T22:42:26.866+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (3feaf0e3bdbf, executor driver, partition 0, NODE_LOCAL, 4472 bytes) taskResourceAssignments Map()
[2022-10-31T22:42:26.872+0000] {subprocess.py:93} INFO - 22/10/31 22:42:26 INFO Executor: Running task 0.0 in stage 3.0 (TID 2)
[2022-10-31T22:42:27.044+0000] {subprocess.py:93} INFO - 22/10/31 22:42:27 INFO ShuffleBlockFetcherIterator: Getting 1 (30.7 KiB) non-empty blocks including 1 (30.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-10-31T22:42:27.051+0000] {subprocess.py:93} INFO - 22/10/31 22:42:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 48 ms
[2022-10-31T22:42:27.105+0000] {subprocess.py:93} INFO - 22/10/31 22:42:27 INFO Executor: Finished task 0.0 in stage 3.0 (TID 2). 12680 bytes result sent to driver
[2022-10-31T22:42:27.113+0000] {subprocess.py:93} INFO - 22/10/31 22:42:27 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 251 ms on 3feaf0e3bdbf (executor driver) (1/1)
[2022-10-31T22:42:27.128+0000] {subprocess.py:93} INFO - 22/10/31 22:42:27 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2022-10-31T22:42:27.132+0000] {subprocess.py:93} INFO - 22/10/31 22:42:27 INFO DAGScheduler: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.357 s
[2022-10-31T22:42:27.143+0000] {subprocess.py:93} INFO - 22/10/31 22:42:27 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-10-31T22:42:27.146+0000] {subprocess.py:93} INFO - 22/10/31 22:42:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2022-10-31T22:42:27.150+0000] {subprocess.py:93} INFO - 22/10/31 22:42:27 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.441313 s
[2022-10-31T22:42:27.290+0000] {subprocess.py:93} INFO - 22/10/31 22:42:27 INFO CodeGenerator: Code generated in 65.075334 ms
[2022-10-31T22:42:27.308+0000] {subprocess.py:93} INFO - 22/10/31 22:42:27 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 1032.0 KiB, free 433.3 MiB)
[2022-10-31T22:42:27.373+0000] {subprocess.py:93} INFO - 22/10/31 22:42:27 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 433.3 MiB)
[2022-10-31T22:42:27.385+0000] {subprocess.py:93} INFO - 22/10/31 22:42:27 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 3feaf0e3bdbf:42787 (size: 14.7 KiB, free: 434.4 MiB)
[2022-10-31T22:42:27.418+0000] {subprocess.py:93} INFO - 22/10/31 22:42:27 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2022-10-31T22:42:27.494+0000] {subprocess.py:93} INFO - 22/10/31 22:42:27 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2022-10-31T22:42:28.169+0000] {subprocess.py:93} INFO - 22/10/31 22:42:28 INFO CodeGenerator: Code generated in 374.258375 ms
[2022-10-31T22:42:28.797+0000] {subprocess.py:93} INFO - 22/10/31 22:42:28 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 3feaf0e3bdbf:42787 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2022-10-31T22:42:28.958+0000] {subprocess.py:93} INFO - 22/10/31 22:42:28 INFO DAGScheduler: Registering RDD 10 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 2
[2022-10-31T22:42:28.969+0000] {subprocess.py:93} INFO - 22/10/31 22:42:28 INFO DAGScheduler: Got map stage job 3 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-10-31T22:42:28.977+0000] {subprocess.py:93} INFO - 22/10/31 22:42:28 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (save at NativeMethodAccessorImpl.java:0)
[2022-10-31T22:42:28.985+0000] {subprocess.py:93} INFO - 22/10/31 22:42:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2022-10-31T22:42:28.997+0000] {subprocess.py:93} INFO - 22/10/31 22:42:28 INFO DAGScheduler: Missing parents: List()
[2022-10-31T22:42:29.015+0000] {subprocess.py:93} INFO - 22/10/31 22:42:29 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[10] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-10-31T22:42:29.052+0000] {subprocess.py:93} INFO - 22/10/31 22:42:29 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 45.9 KiB, free 433.3 MiB)
[2022-10-31T22:42:29.063+0000] {subprocess.py:93} INFO - 22/10/31 22:42:29 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 21.7 KiB, free 433.3 MiB)
[2022-10-31T22:42:29.067+0000] {subprocess.py:93} INFO - 22/10/31 22:42:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 3feaf0e3bdbf:42787 (size: 21.7 KiB, free: 434.4 MiB)
[2022-10-31T22:42:29.075+0000] {subprocess.py:93} INFO - 22/10/31 22:42:29 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513
[2022-10-31T22:42:29.081+0000] {subprocess.py:93} INFO - 22/10/31 22:42:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[10] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-10-31T22:42:29.086+0000] {subprocess.py:93} INFO - 22/10/31 22:42:29 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2022-10-31T22:42:29.091+0000] {subprocess.py:93} INFO - 22/10/31 22:42:29 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (3feaf0e3bdbf, executor driver, partition 0, NODE_LOCAL, 4461 bytes) taskResourceAssignments Map()
[2022-10-31T22:42:29.094+0000] {subprocess.py:93} INFO - 22/10/31 22:42:29 INFO Executor: Running task 0.0 in stage 5.0 (TID 3)
[2022-10-31T22:42:29.258+0000] {subprocess.py:93} INFO - 22/10/31 22:42:29 INFO ShuffleBlockFetcherIterator: Getting 1 (10.5 KiB) non-empty blocks including 1 (10.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-10-31T22:42:29.261+0000] {subprocess.py:93} INFO - 22/10/31 22:42:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2022-10-31T22:42:29.321+0000] {subprocess.py:93} INFO - 22/10/31 22:42:29 INFO CodeGenerator: Code generated in 30.517959 ms
[2022-10-31T22:42:29.373+0000] {subprocess.py:93} INFO - 22/10/31 22:42:29 INFO CodeGenerator: Code generated in 43.483584 ms
[2022-10-31T22:42:29.577+0000] {subprocess.py:93} INFO - 22/10/31 22:42:29 INFO CodeGenerator: Code generated in 137.518875 ms
[2022-10-31T22:42:29.762+0000] {subprocess.py:93} INFO - 22/10/31 22:42:29 INFO CodeGenerator: Code generated in 93.218625 ms
[2022-10-31T22:42:30.029+0000] {subprocess.py:93} INFO - 22/10/31 22:42:30 INFO Executor: Finished task 0.0 in stage 5.0 (TID 3). 4831 bytes result sent to driver
[2022-10-31T22:42:30.046+0000] {subprocess.py:93} INFO - 22/10/31 22:42:30 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 958 ms on 3feaf0e3bdbf (executor driver) (1/1)
[2022-10-31T22:42:30.059+0000] {subprocess.py:93} INFO - 22/10/31 22:42:30 INFO DAGScheduler: ShuffleMapStage 5 (save at NativeMethodAccessorImpl.java:0) finished in 1.027 s
[2022-10-31T22:42:30.077+0000] {subprocess.py:93} INFO - 22/10/31 22:42:30 INFO DAGScheduler: looking for newly runnable stages
[2022-10-31T22:42:30.080+0000] {subprocess.py:93} INFO - 22/10/31 22:42:30 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2022-10-31T22:42:30.084+0000] {subprocess.py:93} INFO - 22/10/31 22:42:30 INFO DAGScheduler: running: Set()
[2022-10-31T22:42:30.088+0000] {subprocess.py:93} INFO - 22/10/31 22:42:30 INFO DAGScheduler: waiting: Set()
[2022-10-31T22:42:30.098+0000] {subprocess.py:93} INFO - 22/10/31 22:42:30 INFO DAGScheduler: failed: Set()
[2022-10-31T22:42:30.174+0000] {subprocess.py:93} INFO - 22/10/31 22:42:30 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2022-10-31T22:42:30.218+0000] {subprocess.py:93} INFO - 22/10/31 22:42:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-10-31T22:42:30.384+0000] {subprocess.py:93} INFO - 22/10/31 22:42:30 INFO CodeGenerator: Code generated in 106.239542 ms
[2022-10-31T22:42:30.611+0000] {subprocess.py:93} INFO - 22/10/31 22:42:30 INFO CodeGenerator: Code generated in 51.908708 ms
[2022-10-31T22:42:30.754+0000] {subprocess.py:93} INFO - 22/10/31 22:42:30 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0
[2022-10-31T22:42:30.784+0000] {subprocess.py:93} INFO - 22/10/31 22:42:30 INFO DAGScheduler: Got job 4 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-10-31T22:42:30.794+0000] {subprocess.py:93} INFO - 22/10/31 22:42:30 INFO DAGScheduler: Final stage: ResultStage 8 (save at NativeMethodAccessorImpl.java:0)
[2022-10-31T22:42:30.801+0000] {subprocess.py:93} INFO - 22/10/31 22:42:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
[2022-10-31T22:42:30.816+0000] {subprocess.py:93} INFO - 22/10/31 22:42:30 INFO DAGScheduler: Missing parents: List()
[2022-10-31T22:42:30.848+0000] {subprocess.py:93} INFO - 22/10/31 22:42:30 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[15] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-10-31T22:42:31.015+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 44.7 KiB, free 433.2 MiB)
[2022-10-31T22:42:31.082+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 21.1 KiB, free 433.2 MiB)
[2022-10-31T22:42:31.092+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 3feaf0e3bdbf:42787 (size: 21.1 KiB, free: 434.3 MiB)
[2022-10-31T22:42:31.098+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513
[2022-10-31T22:42:31.111+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[15] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-10-31T22:42:31.122+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2022-10-31T22:42:31.126+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 4) (3feaf0e3bdbf, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2022-10-31T22:42:31.132+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO Executor: Running task 0.0 in stage 8.0 (TID 4)
[2022-10-31T22:42:31.295+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO ShuffleBlockFetcherIterator: Getting 1 (456.0 B) non-empty blocks including 1 (456.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-10-31T22:42:31.300+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2022-10-31T22:42:31.688+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 3feaf0e3bdbf:42787 in memory (size: 21.7 KiB, free: 434.4 MiB)
[2022-10-31T22:42:31.702+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO CodeGenerator: Code generated in 361.210791 ms
[2022-10-31T22:42:31.799+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO Executor: Finished task 0.0 in stage 8.0 (TID 4). 5900 bytes result sent to driver
[2022-10-31T22:42:31.844+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 4) in 736 ms on 3feaf0e3bdbf (executor driver) (1/1)
[2022-10-31T22:42:31.857+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO DAGScheduler: ResultStage 8 (save at NativeMethodAccessorImpl.java:0) finished in 0.921 s
[2022-10-31T22:42:31.862+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-10-31T22:42:31.867+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2022-10-31T22:42:31.878+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2022-10-31T22:42:31.888+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO DAGScheduler: Job 4 finished: save at NativeMethodAccessorImpl.java:0, took 1.123664 s
[2022-10-31T22:42:31.946+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO DAGScheduler: Registering RDD 16 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 3
[2022-10-31T22:42:31.951+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO DAGScheduler: Got map stage job 5 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-10-31T22:42:31.953+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO DAGScheduler: Final stage: ShuffleMapStage 11 (save at NativeMethodAccessorImpl.java:0)
[2022-10-31T22:42:31.956+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
[2022-10-31T22:42:31.959+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO DAGScheduler: Missing parents: List()
[2022-10-31T22:42:31.960+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[16] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-10-31T22:42:31.989+0000] {subprocess.py:93} INFO - 22/10/31 22:42:31 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 44.6 KiB, free 433.2 MiB)
[2022-10-31T22:42:32.003+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 21.2 KiB, free 433.2 MiB)
[2022-10-31T22:42:32.009+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 3feaf0e3bdbf:42787 (size: 21.2 KiB, free: 434.3 MiB)
[2022-10-31T22:42:32.021+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513
[2022-10-31T22:42:32.024+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[16] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-10-31T22:42:32.031+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2022-10-31T22:42:32.034+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 5) (3feaf0e3bdbf, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
[2022-10-31T22:42:32.037+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO Executor: Running task 0.0 in stage 11.0 (TID 5)
[2022-10-31T22:42:32.087+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO ShuffleBlockFetcherIterator: Getting 1 (456.0 B) non-empty blocks including 1 (456.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-10-31T22:42:32.099+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
[2022-10-31T22:42:32.162+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO Executor: Finished task 0.0 in stage 11.0 (TID 5). 5655 bytes result sent to driver
[2022-10-31T22:42:32.165+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 5) in 145 ms on 3feaf0e3bdbf (executor driver) (1/1)
[2022-10-31T22:42:32.169+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2022-10-31T22:42:32.179+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO DAGScheduler: ShuffleMapStage 11 (save at NativeMethodAccessorImpl.java:0) finished in 0.207 s
[2022-10-31T22:42:32.187+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO DAGScheduler: looking for newly runnable stages
[2022-10-31T22:42:32.194+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO DAGScheduler: running: Set()
[2022-10-31T22:42:32.200+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO DAGScheduler: waiting: Set()
[2022-10-31T22:42:32.204+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO DAGScheduler: failed: Set()
[2022-10-31T22:42:32.209+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2022-10-31T22:42:32.386+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO CodeGenerator: Code generated in 150.339542 ms
[2022-10-31T22:42:32.621+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0
[2022-10-31T22:42:32.633+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO DAGScheduler: Got job 6 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-10-31T22:42:32.639+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO DAGScheduler: Final stage: ResultStage 15 (save at NativeMethodAccessorImpl.java:0)
[2022-10-31T22:42:32.643+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
[2022-10-31T22:42:32.655+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO DAGScheduler: Missing parents: List()
[2022-10-31T22:42:32.674+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[21] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-10-31T22:42:32.789+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 47.8 KiB, free 433.2 MiB)
[2022-10-31T22:42:32.812+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 22.3 KiB, free 433.1 MiB)
[2022-10-31T22:42:32.820+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 3feaf0e3bdbf:42787 (size: 22.3 KiB, free: 434.3 MiB)
[2022-10-31T22:42:32.831+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513
[2022-10-31T22:42:32.843+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[21] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-10-31T22:42:32.860+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2022-10-31T22:42:32.866+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 6) (3feaf0e3bdbf, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2022-10-31T22:42:32.883+0000] {subprocess.py:93} INFO - 22/10/31 22:42:32 INFO Executor: Running task 0.0 in stage 15.0 (TID 6)
[2022-10-31T22:42:33.097+0000] {subprocess.py:93} INFO - 22/10/31 22:42:33 INFO ShuffleBlockFetcherIterator: Getting 1 (456.0 B) non-empty blocks including 1 (456.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-10-31T22:42:33.102+0000] {subprocess.py:93} INFO - 22/10/31 22:42:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
[2022-10-31T22:42:33.160+0000] {subprocess.py:93} INFO - 22/10/31 22:42:33 INFO CodeGenerator: Code generated in 43.837541 ms
[2022-10-31T22:42:33.211+0000] {subprocess.py:93} INFO - 22/10/31 22:42:33 INFO CodeGenerator: Code generated in 16.453125 ms
[2022-10-31T22:42:33.303+0000] {subprocess.py:93} INFO - 22/10/31 22:42:33 INFO CodeGenerator: Code generated in 12.177041 ms
[2022-10-31T22:42:33.387+0000] {subprocess.py:93} INFO - 22/10/31 22:42:33 INFO Executor: Finished task 0.0 in stage 15.0 (TID 6). 6226 bytes result sent to driver
[2022-10-31T22:42:33.398+0000] {subprocess.py:93} INFO - 22/10/31 22:42:33 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 6) in 560 ms on 3feaf0e3bdbf (executor driver) (1/1)
[2022-10-31T22:42:33.402+0000] {subprocess.py:93} INFO - 22/10/31 22:42:33 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2022-10-31T22:42:33.411+0000] {subprocess.py:93} INFO - 22/10/31 22:42:33 INFO DAGScheduler: ResultStage 15 (save at NativeMethodAccessorImpl.java:0) finished in 0.723 s
[2022-10-31T22:42:33.415+0000] {subprocess.py:93} INFO - 22/10/31 22:42:33 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-10-31T22:42:33.417+0000] {subprocess.py:93} INFO - 22/10/31 22:42:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
[2022-10-31T22:42:33.427+0000] {subprocess.py:93} INFO - 22/10/31 22:42:33 INFO DAGScheduler: Job 6 finished: save at NativeMethodAccessorImpl.java:0, took 0.793125 s
[2022-10-31T22:42:33.770+0000] {subprocess.py:93} INFO - 22/10/31 22:42:33 INFO SparkContext: Invoking stop() from shutdown hook
[2022-10-31T22:42:33.864+0000] {subprocess.py:93} INFO - 22/10/31 22:42:33 INFO SparkUI: Stopped Spark web UI at http://3feaf0e3bdbf:4040
[2022-10-31T22:42:33.978+0000] {subprocess.py:93} INFO - 22/10/31 22:42:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2022-10-31T22:42:34.247+0000] {subprocess.py:93} INFO - 22/10/31 22:42:34 INFO MemoryStore: MemoryStore cleared
[2022-10-31T22:42:34.251+0000] {subprocess.py:93} INFO - 22/10/31 22:42:34 INFO BlockManager: BlockManager stopped
[2022-10-31T22:42:34.497+0000] {subprocess.py:93} INFO - 22/10/31 22:42:34 INFO BlockManagerMaster: BlockManagerMaster stopped
[2022-10-31T22:42:34.514+0000] {subprocess.py:93} INFO - 22/10/31 22:42:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2022-10-31T22:42:35.010+0000] {subprocess.py:93} INFO - 22/10/31 22:42:34 INFO SparkContext: Successfully stopped SparkContext
[2022-10-31T22:42:35.025+0000] {subprocess.py:93} INFO - 22/10/31 22:42:34 INFO ShutdownHookManager: Shutdown hook called
[2022-10-31T22:42:35.063+0000] {subprocess.py:93} INFO - 22/10/31 22:42:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-3dc78c7c-7817-487b-a930-c1cdc7953540
[2022-10-31T22:42:35.081+0000] {subprocess.py:93} INFO - 22/10/31 22:42:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-3dc78c7c-7817-487b-a930-c1cdc7953540/pyspark-d76e5287-4fc6-44e0-8b6b-712e61874968
[2022-10-31T22:42:35.086+0000] {subprocess.py:93} INFO - 22/10/31 22:42:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-9e6d82f7-7f0c-4aa8-8904-c369a6e56a91
[2022-10-31T22:42:37.751+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2022-10-31T22:42:37.929+0000] {taskinstance.py:1406} INFO - Marking task as SUCCESS. dag_id=j_spark_trigger, task_id=transform_data_2, execution_date=20221031T224141, start_date=20221031T224144, end_date=20221031T224237
[2022-10-31T22:42:38.059+0000] {local_task_job.py:164} INFO - Task exited with return code 0
[2022-10-31T22:42:38.096+0000] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
